---
title: 回帰モデルの効果量
author: Akira Terui
date: '2021-03-23'
slug: []
categories: []
tags:
  - regression
  - R
math: true
output:
  blogdown::html_page:
    toc: true
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>

<div id="TOC">
<ul>
<li><a href="#効果量としての標準化偏回帰係数">効果量としての標準化偏回帰係数</a></li>
<li><a href="#average-predictive-comparison">Average predictive comparison</a></li>
<li><a href="#rで実装">Rで実装</a></li>
</ul>
</div>

<div id="効果量としての標準化偏回帰係数" class="section level2">
<h2>効果量としての標準化偏回帰係数</h2>
<p>線形回帰は、生態学の一般的な解析手法になっている。Rで多数の関数が用意されているため解析も容易で、回帰係数の95%信頼区間やp値などでその効果の有意性もカンタンに検討できる。一方、近頃では有意性だけでなく、「効果量（Effect size）」にも注目したほうがいいとの見方が広まっている。この効果量には様々な指標があるけれども、線形回帰の文脈でいえば標準化偏回帰係数がもっとも広く使われている。</p>
<p>そもそも偏回帰係数の意味とは何かというと、対応する説明変数xが単位量（つまり1.0）だけ増えたときに、応答変数がどれだけ変化するかを示している。しかし、説明変数間で単位<sup>*1</sup>が違うと（例えばある変数はm単位で計られているのに対し、別の変数は㎝単位で計られている）、偏回帰係数はその単位の違いの影響を直に受けてしまう。そこで、それぞれの説明変数をそのばらつき（標準偏差SD）で割り（標準化）、それら標準化された説明変数に対する偏回帰係数を推定する。標準化された説明変数の単位はそろっているので、推定された標準化偏回帰係数も比較できるものになっているはず、というものだ。</p>
<p>しかし、これには一つの問題がある。現代の一般的な統計モデルでは、効果量としての標準化偏回帰係数の解釈が「直感的ではない」のである。例としては以下のようなものがある。個体数のカウントデータを線形モデルで表現する場合、誤差構造としてはポアソン分布（あるいは負の二項分布）を用いることが多い。ポアソン分布の平均パラメータは負の値をとることができないので、Rではデフォルトで対数リンク関数が実装されている。この時、ポアソンモデルの偏回帰係数のなにがどう「直感的」でないのか、下の例を見ながら考えてみる。</p>
<p>まず、下記のスクリプトで簡単な仮想データを作る。</p>
<pre class="r"><code># simulated data 
set.seed(111)
n_sample &lt;- 100
x1 &lt;- rnorm(n_sample, mean = 10, sd = 1)
x2 &lt;- rnorm(n_sample, mean = 10, sd = 3)
X &lt;- model.matrix(~ x1 + x2)
b &lt;- c(0.1, 0.2, 0.2) # true parameters
y &lt;- rpois(n_sample, exp(X %*% b)) # simulated y</code></pre>
<p>ポアソン分布を仮定したGLMを当てはめる。</p>
<p><span class="math display">\[
y_i \sim Pois(\lambda_i)\\    
ln \lambda_i = \alpha + \beta_1 x_{1,i} + \beta_2 x_{2,i}
\]</span></p>
<pre class="r"><code># model fit; unstandardized
m &lt;- glm(y ~ x1 + x2, family = poisson)
coef(m)</code></pre>
<pre><code>## (Intercept)          x1          x2 
##   0.2210261   0.1902442   0.1991515</code></pre>
<p>推定された回帰係数を見ると、真のパラメータを良く推定出来ていることがわかる。ただし、上の例では標準化されていない説明変数をつかっているので、<code>x1</code>と<code>x2</code>の係数の値を直接比較することはできない。そこで、これらの変数を標準化して、もう一度モデルを当てはめる。</p>
<pre class="r"><code># model fit; standardized
m &lt;- glm(y ~ scale(x1) + scale(x2), family = poisson)
coef(m)</code></pre>
<pre><code>## (Intercept)   scale(x1)   scale(x2) 
##   4.1024669   0.2037239   0.6089030</code></pre>
<p>もともとの偏回帰係数は同程度だったが、標準化すると<code>x2</code>の効果のほうが相対的に大きいことがわかる（<code>x2</code>のSDが大きいため）。</p>
<p>たしかに相対比較はできるけれども、問題は<strong>この回帰係数が対数スケールで推定されている点</strong>にある。係数は、「説明変数が単位量変化したときの応答変数の変化量（厳密にはその期待値）」と説明したが、ポアソンモデルでは対数リンク関数を使うので、回帰係数が対数変換された応答変数に対する効果になってしまう。つまり、このモデルで言えば、<code>x1</code>が1.0だけ増えた時、対数変換された<span class="math inline">\(ln~y\)</span>が0.2だけ増えると解釈しなければならない。別にそれでいいではないか、と思ってしまいがちだが、この問題は実はそうシンプルではない。なぜなら、対数変換は非線形な変数変換のため、<code>x1</code>の変化量は同じでも、起点と終点に応じて元のスケールでの応答変数（つまり個体数）の変化量が変わってしまう（下図）。このため、係数の解釈をする場合に、単純に<strong>「<code>x1</code>を単位量だけ増やしたら、個体数はこれだけ増える」とは言えない</strong>。</p>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>この問題はポアソンモデルに限ったものではない。二項分布を仮定するGLMでは、応答変数をロジット変換するため同様の現象がおきる。また、正規分布のようなリンク関数を用いないモデルであっても、説明変数に交互作用がある場合には同様の問題が生じる。さらに他の共変量の効果もあることを考えるとどうだろう？もう複雑すぎて、とても手に負えたものではない。</p>
</div>
<div id="average-predictive-comparison" class="section level2">
<h2>Average predictive comparison</h2>
<p>これらの問題に対処するため、<a href="https://journals.sagepub.com/doi/abs/10.1111/j.1467-9531.2007.00181.x?casa_token=T6DzGVcizjIAAAAA:80aPZ6SPlcLHoaDh6X91tZv8O-1UGuivUEyeXGmbov1faoI1qoRSRjxYEXapifWWYOIDW9-CrJKt-Q">Gelman and Pardoe (2007)</a>はAverage predictive comparisonと呼ばれる手法を提案している。非線形な変数変換も交互作用もないモデルの場合、この手法の推定値は偏回帰係数と全く同じになる。しかし、この手法では、非線形な変数変換が伴う場合でも、応答変数の元のスケールで各説明変数の効果量が比べられる点に大きなメリットがある。</p>
<p>この手法を<a href="https://journals.sagepub.com/doi/abs/10.1111/j.1467-9531.2007.00181.x?casa_token=T6DzGVcizjIAAAAA:80aPZ6SPlcLHoaDh6X91tZv8O-1UGuivUEyeXGmbov1faoI1qoRSRjxYEXapifWWYOIDW9-CrJKt-Q">Gelman and Pardoe (2007)</a>に沿って説明してみる。まず、効果量に興味のある説明変数の値<span class="math inline">\(u\)</span>とそれ以外説明変数の値<span class="math inline">\(v\)</span>に分けて考える。まず、ある任意の<span class="math inline">\(u\)</span>の変化（<span class="math inline">\(u^{(1)} \to u^{(2)}\)</span>）から期待される<span class="math inline">\(y\)</span>の変化量<span class="math inline">\(\delta_u\)</span>を求める（basic prediction comparison）。</p>
<p><span class="math display">\[
\delta_u(u^{(1)} \to u^{(2)}, v, \Theta) = \frac{E(y|u^{(2)}, v, \Theta) - E(y|u^{(1)}, v, \Theta)}{u^{(2)} - u^{(1)}}
\]</span></p>
<p>ここで<span class="math inline">\(E(\cdot)\)</span>は任意の関数（多くの場合、リンク関数の逆関数）、<span class="math inline">\(\Theta\)</span>は線形モデルのパラメータを示している。しかし、先に述べたように、この変化量は<span class="math inline">\(u^{(1)}\)</span>および<span class="math inline">\(u^{(2)}\)</span>、さらには他の説明変数<span class="math inline">\(v\)</span>の影響ももろに受けてしまう。そこで<a href="https://journals.sagepub.com/doi/abs/10.1111/j.1467-9531.2007.00181.x?casa_token=T6DzGVcizjIAAAAA:80aPZ6SPlcLHoaDh6X91tZv8O-1UGuivUEyeXGmbov1faoI1qoRSRjxYEXapifWWYOIDW9-CrJKt-Q">Gelman and Pardoe (2007)</a>はAverage predictive comparisonという量を提案している。</p>
<p><span class="math display">\[
\Delta_u = \frac{\int\int_{u^{(2)}&gt;u^{(1)}}du^{(1)}du^{(2)}\int dv \int d\Theta (E(y|u^{(2)}, v, \Theta) - E(y|u^{(1)}, v, \Theta))~p(u^{(1)}|v)~p(u^{(2)}|v)~p(v)~p(\Theta)}
                  { \int\int_{u^{(2)}&gt;u^{(1)}}du^{(1)}du^{(2)}\int dv \int d\Theta~(u^{(2)} - u^{(1)})~ p(u^{(1)}|v)~p(u^{(2)}|v)~p(v)~p(\Theta) }
\]</span></p>
<p>かなり煩雑な式だが、主な意味は以下の通り。（１）興味のある変数<span class="math inline">\(u\)</span>の効果をみたいのだが、これはいろんな値をとるのですべての組み合わせについて考えて、その平均をとってやる。（２）ただし、<span class="math inline">\(\delta_u\)</span>が他の変数<span class="math inline">\(v\)</span>の影響も受けるので、<span class="math inline">\(u\)</span>が<span class="math inline">\(u^{(1)}\)</span>から<span class="math inline">\(u^{(2)}\)</span>に変わる時に、<span class="math inline">\(v\)</span>は変化しないという条件付き確率とってあげる。（３）パラメータ推定の不確実性も考えて、その分布の積分をとる（ベイズの場合；頻度主義の場合は推定値とSEから仮想的な確率分布を考えると思われる）。ただ、理論的には正しいのだが、これを有限なデータセットにそのまま適用するのは無理がある。特に<span class="math inline">\(p(u^{(1)}|v)\)</span>と<span class="math inline">\(p(u^{(2)}|v)\)</span>を推定できるようなデータセットはまず存在しないだろう（ある二点のデータポイントを考えた時、興味の変数以外が全く同じということはまずありえないので）。代わりに、<a href="https://journals.sagepub.com/doi/abs/10.1111/j.1467-9531.2007.00181.x?casa_token=T6DzGVcizjIAAAAA:80aPZ6SPlcLHoaDh6X91tZv8O-1UGuivUEyeXGmbov1faoI1qoRSRjxYEXapifWWYOIDW9-CrJKt-Q">Gelman and Pardoe (2007)</a>は、以下の近似式を用いてこの量を推定することを提案している。</p>
<p><span class="math display">\[
\hat\Delta_u = \frac{\sum_{i=1}^n \sum_{j=1}^n \sum_{s=1}^S w_{ij}(E(y|u_j, v_i, \Theta_s) - E(y|u_i, v_i, \Theta_s))sign(u_j - u_i)}
                      {\sum_{i=1}^n \sum_{j=1}^n \sum_{s=1}^S w_{ij}(u_j - u_i)sign(u_j - u_i)}
\]</span></p>
<p>ここでは、<span class="math inline">\(i\)</span>および<span class="math inline">\(j\)</span>が各データポイントを表しており、それらすべての組み合わせについて和をとることで、<span class="math inline">\(\int\int_{u^{(2)}&gt;u^{(1)}}du^{(1)}du^{(2)}\)</span>を近似している。<span class="math inline">\(s\)</span>はパラメータの繰り返しを示しており、ベイズの枠組みで言えば個々のMCMCサンプルが該当するといえば分かりやすいかと思う。この式の肝は<span class="math inline">\(w_{ij}\)</span>にある。これは<span class="math inline">\(p(u^{(1)}|v)\)</span>と<span class="math inline">\(p(u^{(2)}|v)\)</span>を近似するための重み付け関数で、<a href="https://journals.sagepub.com/doi/abs/10.1111/j.1467-9531.2007.00181.x?casa_token=T6DzGVcizjIAAAAA:80aPZ6SPlcLHoaDh6X91tZv8O-1UGuivUEyeXGmbov1faoI1qoRSRjxYEXapifWWYOIDW9-CrJKt-Q">Gelman and Pardoe (2007)</a>はマハラノビス距離にもとづく以下の関数を提案している。</p>
<p><span class="math display">\[
w_{ij} = w(v_i, v_j) = \frac{1}{1 + (v_i - v_j)^T\Omega_v^{-1}(v_i-v_j)}
\]</span></p>
<p>上の式のうち、<span class="math inline">\((v_i - v_j)^T\Omega_v^{-1}(v_i-v_j)\)</span>の部分がマハラノビス距離の平方に相当する（マハラノビス距離については<a href="https://toukei-lab.com/mahalanobis">こちら</a>を参照）。この式では、<span class="math inline">\(v_i\)</span>と<span class="math inline">\(v_j\)</span>のマハラノビス距離が遠くなるほど、その<span class="math inline">\(i\)</span>と<span class="math inline">\(j\)</span>のペアにより小さな重みを与えるようになっている（なお、<span class="math inline">\(v\)</span>は複数の説明変数からなるベクターであることが一般的なので、多変量空間で共分散を考慮した距離を計るマハラノビス距離を使う）。もともと、「<span class="math inline">\(v\)</span>は一定のまま、<span class="math inline">\(u\)</span>は<span class="math inline">\(u^{(1)}\)</span>から<span class="math inline">\(u^{(2)}\)</span>に変わる」という状況を考えたい。しかし、実際にそんなデータポイントの組み合わせを見つけるのは難しい。なので、<span class="math inline">\(u_i\)</span>（このとき<span class="math inline">\(v = v_i\)</span>）から<span class="math inline">\(u_j\)</span>（このとき<span class="math inline">\(v = v_j\)</span>）になるとき、<span class="math inline">\(v\)</span>が大きく変化するようなデータポイントの組み合わせには小さな重みを与えよう、という発想なのだ（<span class="math inline">\(v_i = v_j\)</span>の場合には<span class="math inline">\(w_{ij} = 1\)</span>となる；Gelmanさん天才）。</p>
<p>実際の計算では、パラメータのMCMCサンプル（ベイズ）あるいは仮想的な確率分布（頻度主義）から得られる繰り返しを考え、次のように計算する。</p>
<p><span class="math display">\[
\hat \Delta_{u} = \frac{1}{S} \sum_{s=1}^S \hat \Delta_{u,s}
\]</span></p>
<p>ここで、<span class="math inline">\(S\)</span>はパラメータの繰り返しの総数を示す。それぞれのパラメータセット<span class="math inline">\(s\)</span>についてAverage predictive comparisonを上の式に沿って定義する。</p>
<p><span class="math display">\[
\hat \Delta_{u,s} = \frac{\sum_{i=1}^n \sum_{j=1}^n w_{ij}(E(y|u_j, v_i, \Theta_s) - E(y|u_i, v_i, \Theta_s))sign(u_j - u_i)}
                           {\sum_{i=1}^n \sum_{j=1}^n w_{ij}(u_j - u_i)sign(u_j - u_i)}
\]</span></p>
<p>SEは下記の式から得ることができる。</p>
<p><span class="math display">\[
S.E.(\hat \Delta_{u,s}) = \sqrt{\frac{1}{S-1} \sum_{s=1}^S (\hat \Delta_{u,s} - \hat \Delta_{u})^2}
\]</span></p>
</div>
<div id="rで実装" class="section level2">
<h2>Rで実装</h2>
<p>こんな素晴らしい手法、なぜ生態学の界隈で広がっていないのか。どうせRのパッケージくらい誰かが作ってるんだろう。と思い、<strong>検索したらなかった。</strong>というわけで自分で関数を書いてパッケージ化した<sup>*2</sup>。まだ試作段階だが、使い方は以下の通り。</p>
<p>以下のスクリプトを実行してパッケージをインストールする。</p>
<pre class="r"><code>remotes::install_github(&quot;aterui/avpc&quot;)</code></pre>
<p>今のところ一番ベーシックな関数である<code>apcomp</code>というものしか実装できていない。追って補足的な関数を実装する予定だけど、ひとまずこれで基本的なことはできる。先のポアソンモデルの例をもう一度使うことにする。</p>
<pre class="r"><code># simulated data 
set.seed(111)
n_sample &lt;- 100
x1 &lt;- rnorm(n_sample, mean = 10, sd = 1)
x2 &lt;- rnorm(n_sample, mean = 10, sd = 3)
X &lt;- model.matrix(~ x1 + x2)
b &lt;- c(0.1, 0.2, 0.2) # true parameters
y &lt;- rpois(n_sample, exp(X %*% b)) # simulated y

# model fit; unstandardized
m &lt;- glm(y ~ x1 + x2, family = poisson)</code></pre>
<p>このとき、モデルの説明変数は<strong>標準化しないことを推奨</strong>。関数<code>apcomp</code>ではxが1だけ変化したときのyの変化量をみるので、元の数値の単位が維持されているほうが解釈しやすい（1m増えたら個体数はこれだけ増える；1g増えたら個体数はこれだけ増える、などなど）。このモデルを関数<code>apcomp</code>に突っ込み、引数<code>u</code>に興味のある変数を指定するだけ。</p>
<pre class="r"><code>library(avpc)
re &lt;- apcomp(m, u = &quot;x1&quot;)</code></pre>
<pre><code>## the inverse function of log was used to back-transform the response variable y</code></pre>
<p>返り値は<code>estimate</code>、<code>sim_estimate</code>、<code>sim_se</code>、<code>df_uv</code>、<code>df_u1v1</code>、<code>df_u2v1</code>、<code>interaction_term</code>があるが、直接関係あるのは最初の三つ。<code>estimate</code>は線形モデルの点推定値を用いた時のAverage predictive comparison（APC）の値。なので、モデルに相加的な項しかなく、変数変換もない場合、この返り値は偏回帰係数と一致する。<code>sim_estimate</code>は、モデルパラメータの推定値を平均、SEを標準偏差とする正規分布からランダムに1000個引っ張ってきて平均をとったAPCの値（シミュレーションの数は 引数<code>n_sim</code>で指定できる）。<code>sim_se</code>はその標準誤差（定義は上述）。</p>
<pre class="r"><code>re$estimate</code></pre>
<pre><code>## [1] 13.70707</code></pre>
<pre class="r"><code>re$sim_estimate</code></pre>
<pre><code>## [1] 13.99792</code></pre>
<pre class="r"><code>re$sim_se</code></pre>
<pre><code>## [1] 3.091321</code></pre>
<p>この関数を使うと、ポアソンモデルを使った場合でも、<code>x1</code>が1増えた時に個体数は14増える！のように言えるので、直感的な効果量の比較が可能になる。<code>apply</code>familyの関数などと組み合わせれば、複数の説明変数の項かも一挙に推定できる。</p>
<pre class="r"><code>input &lt;- c(&quot;x1&quot;, &quot;x2&quot;)
sapply(input, function(x) apcomp(m, u = x))</code></pre>
<pre><code>## the inverse function of log was used to back-transform the response variable y
## the inverse function of log was used to back-transform the response variable y</code></pre>
<pre><code>##                  x1       x2      
## estimate         13.70707 13.22086
## sim_estimate     14.12767 13.34761
## sim_se           2.98127  2.333258
## interaction_term NULL     NULL    
## df_uv            List,9   List,9  
## df_u1v1          List,3   List,3  
## df_u2v1          List,3   List,3</code></pre>
<p>今のところモデルクラス<code>lm</code>、<code>lmerMod</code>、<code>rlm</code>、<code>glm</code>にしか対応してないけど、時間のあるときに<code>brms</code>なんかにも対応できるようにしたい。</p>
<p><sup>*1</sup>厳密にはSD</p>
<p><sup>*2</sup>エラーなどあったらぜひhanabi0111 at gmail.com連絡ください。ただし、利用に関して、責任などは一切負えないのでご承知を。</p>
</div>
